{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "[Conventions](#conventions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conventions\n",
    "__Number of training examples__: $M$\n",
    "\n",
    "__Number of features__: $N$\n",
    "\n",
    "__Design matrix__: $X$<br>\n",
    "The design matrix $X$ is a matrix $X \\in \\mathbb{R}^{M, N}$ with rows $X[i, :].reshape(1, N) \\in \\mathbb{R}^{1, N}$, and columns $X[:, i].reshape(M, 1) \\in \\mathbb{R}^{M, 1}$\n",
    "\n",
    "__Output Vector__: $Y$<br>\n",
    "The output vector $Y$ is a matrix $Y \\in \\mathbb{R}^{M, 1}$ that our model will be evaluated against \n",
    "\n",
    "__Parameter vector__: $\\theta$<br>\n",
    "The parameter vector $\\theta$ is a matrix $\\theta \\in \\mathbb{R}^{N, 1}$ that parameterizes our hypothesis\n",
    "\n",
    "__Hypothesis__: $H$<br>\n",
    "The hypothesis $H$ is a function $H(\\theta, x): \\mathbb{R}^{N, 1}, \\mathbb{R}^{1, N} \\to \\mathbb{R}$ that models our data\n",
    "\n",
    "__Learning rate__: $\\alpha$\n",
    "\n",
    "__Regularization Constant__: $\\lambda$\n",
    "\n",
    "__Normalizaing Constant__: $K$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_raw = np.genfromtxt('monks-1.csv', delimiter=',')\n",
    "_DATA = _raw[:, 0:7]\n",
    "X = _raw[:, 1:7]\n",
    "Y = _raw[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = Y.size\n",
    "N = X.shape[1]\n",
    "ALPHA = 0.1\n",
    "H = lambda x: (1 / (1 + np.exp(-x @ theta)))\n",
    "K = 1/float(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addFeatures(X):\n",
    "    col = lambda i: X[:, i].reshape(M, 1)\n",
    "    sq = lambda x: np.multiply(x, x)\n",
    "    a, b, c = sq(col(0)), sq(col(1)), sq(col(4))\n",
    "    res = np.concatenate((X, a, b, c), 1)\n",
    "    return res\n",
    "X = addFeatures(X)\n",
    "N = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(theta: np.array) -> float:\n",
    "    '''\n",
    "    param: theta, parameter vector\n",
    "    returns: cost that theta incurs on your data\n",
    "    '''\n",
    "    sum = 0\n",
    "    for i in range(M):\n",
    "        x, y = X[i].reshape(1, N), Y[i] # transfer\n",
    "        sum += - (y * np.log(H(x))) - ((1 - y) * np.log(1 - H(x)))\n",
    "    return sum\n",
    "\n",
    "def accuracy(theta: np.array):\n",
    "    correct = 0;\n",
    "    threshold = 0.5\n",
    "    for i in range(M):\n",
    "        x, y = X[i].reshape(1, N), Y[i]\n",
    "        pos, neg = y == 1 and H(x) >= threshold, y == 0 and H(x) < threshold\n",
    "        correct += 1 if pos or neg else 0\n",
    "    return correct/float(M)\n",
    "\n",
    "def distances(theta: np.ndarray) -> np.ndarray:\n",
    "    '''\n",
    "    param: theta, parameter vector\n",
    "    returns: an array of differences between the model and the actual values\n",
    "    '''\n",
    "    res = np.zeros(M)\n",
    "    for i in range(M):\n",
    "        x, y = X[i].reshape(1, N), Y[i] # transfer\n",
    "        res[i] = H(x) - y\n",
    "    return res.reshape(M, 1)\n",
    "\n",
    "def descend(theta):\n",
    "    inf = X @ distances(theta)\n",
    "    inf = -ALPHA * K * inf\n",
    "    return theta + inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (432,9) and (432,1) not aligned: 9 (dim 1) != 432 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-135-4fcd0832a86d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mITERATIONS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdescend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'cost {cost(theta)} accuracy {accuracy(theta)} theta {theta}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-134-9c7cfdd366b3>\u001b[0m in \u001b[0;36mdescend\u001b[1;34m(theta)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdescend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0minf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mdistances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0minf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mALPHA\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mK\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0minf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtheta\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (432,9) and (432,1) not aligned: 9 (dim 1) != 432 (dim 0)"
     ]
    }
   ],
   "source": [
    "theta = np.zeros(X.shape[1]).reshape(N, 1)\n",
    "ITERATIONS = 300\n",
    "for i in range(ITERATIONS):\n",
    "    print(theta)\n",
    "    theta = descend(theta)\n",
    "print(f'cost {cost(theta)} accuracy {accuracy(theta)} theta {theta}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
