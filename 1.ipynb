{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating Linear Regression With an Iterative Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "[Introduction](#introduction)<br>\n",
    "[Notation](#notation)<br>\n",
    "[Gradient Descent](#gradientDescent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a id='introduction'></a>\n",
    "\n",
    "In the second lecture of Andrew Ng's machine learning __[lecture series](https://www.youtube.com/watch?v=UzxYlbK2c7E&list=PLA89DCFA6ADACE599)__ he talked about a learning algorithm that could approximate the line of best fit of a data set by iteratively minimizing the squared distance between our model and the data set. Following is a brief explanation and implementation of the algorithm in Python. We will test our algorithm on a data set courtesy of __[Siraj Raval](https://github.com/llSourcell)__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notation <a id='notation'></a>\n",
    "\n",
    "__Training Data__\n",
    "\n",
    "- $(x^{(i)},y^{(i)})$\n",
    "\n",
    "Our training data consists of a set of $m$ ordered lists $(x, y)$, where $x$ and $y$ are the dependant and independant variables respectively. We denote our $i^{th}$ training example as $(x^{(i)}, y^{(i)})$.\n",
    "\n",
    "__Model (hypothesis)__\n",
    "\n",
    "- $h(x) = h_{\\theta_0,\\theta_1}(x) = \\theta_0 x + \\theta_1$ or\n",
    "- $h(x_0, x_1) = h-{\\theta_0, \\theta_1}(x_0, x_1) = \\theta_0 x_0 + \\theta_1 x_1$, where $x_1 = 1$\n",
    "\n",
    "Our model $h$ is a fuction whose input is the $x$ values of our training data, and output is an estimate of the corresponding $y$ value of a specific training example. At any given moment, our model is parameterized by the changing variables $\\theta_0,\\theta_1$. It is helpful to think or our model as this equivalent form $h_{\\theta_0,\\theta_1}(x_0, x_1) = \\theta_0 x_0 + \\theta_1 x_1$, where $x_1 = 1$ for convenience later on. You can also think of our model being generated by a model generating function $g: \\mathbb{R}^2 \\to (f:\\mathbb{R}\\to\\mathbb{R})$, where $g(\\theta_0, \\theta_1) = h_{\\theta_0, \\theta_1}(x_0, x_1)$, but I digress.\n",
    "\n",
    "__Loss (Cost)__\n",
    "\n",
    "- $J(\\theta_0, \\theta_1) = \\Sigma_{i=0}^{m}(h(x^{(i)}_0, x^{(i)}_1) - y^{(y)})^2$\n",
    "\n",
    "The loss function $J$ is a measure of the performance of our model, in our case the loss function is the sum of squared distances between our model paramaterized by $\\theta_0, \\theta_1$ and training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA = np.genfromtxt('./res/data.csv', delimiter=',')\n",
    "ALPHA = 0.0001/DATA.size, 0.01/DATA.size\n",
    "ITERATIONS = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first part of our algorithm, we will import the computing and data plotting libraries numpy and matplotlib. We will get our data from csv file. We have a hyperparameter list ALPHA which contains the learning rates for our two parameters $\\theta_0, \\theta_1$. To choose these constants I tried running the algorithm with arbitrary learning rates until I found two numbers that have relatively fast convergence. We can choose to run our algorithm for any number of iterations we want to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent <a id='gradientDescent'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descend(params: list) -> list:\n",
    "    influence0 = lambda datum: ((params[0] * datum[0]) + (params[1] * 1) - datum[1]) * datum[0]\n",
    "    influence1 = lambda datum: ((params[0] * datum[0]) + (params[1] * 1) - datum[1]) * 1\n",
    "    step0 = lambda delta: -(ALPHA[0] * delta[0])\n",
    "    step1 = lambda delta: -(ALPHA[1] * delta[1])\n",
    "    \n",
    "    delta = [0, 0]\n",
    "    for datum in DATA:\n",
    "        delta[0] += influence0(datum)\n",
    "        delta[1] += influence1(datum)\n",
    "    \n",
    "    return [params[0] + step0(delta), params[1] + step1(delta)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rule that our machine will use to learn is called gradient descent. We can start by taking a look at the derivative with respect to $\\theta_0$ of the function $f(\\theta_0) = \\theta_0^2$, $\\frac{\\partial}{\\partial\\theta_0}f(\\theta_0) = \\frac{\\partial}{\\partial\\theta_0}\\theta_0^2 = 2\\theta_0$. When we compute the derivative of $f$ at $\\theta_0=5$, we get the number $10$. Another way to interperet the result $10$ is actually as the vector $(10)$, where $10$ is the height that we would gain if we were to travel $1$ unit in the direction of the vector $(10)$, the positive direction, which also happens to be the direction of steepest ascent at $\\theta_0 = 5$ on $f$. It turns out that this result generalizes to gradients as well, so the gradient of $g(\\theta_0,\\theta_1)=\\theta_0^2\\theta_1 + 2\\theta_1$, denoted $\\nabla g(\\theta_0, \\theta_1) = (\\frac{\\partial}{\\partial\\theta_0}g(\\theta_0, \\theta_1), \\frac{\\partial}{\\partial\\theta_1}g(\\theta_0,\\theta_1)) = (2\\theta_0\\theta_1, \\theta_0^2+2)$. Evaluating the gradient of $g$ at point $(\\theta_0,\\theta_1) = (1,2)$\n",
    "\n",
    "The gradient of a function is just a list of partial derivatives of that function (also known as the multidimensional derivative). It turns out that when you compute the gradient of a function at a specific point, you get a vector that points in the direction of steepest ascent of that function at that point, we will use this property to motivate our learning rule.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the gradient of our loss function $J$, we need to compute the partial derivatives $\\frac{\\partial}{\\partial\\theta_0}J$ and $\\frac{\\partial}{\\partial\\theta_1}J$.\n",
    "\n",
    "$\\frac{\\partial}{\\partial\\theta_0}J = \\frac{\\partial}{\\partial\\theta_0}\\Sigma_{i=0}^{m}(h(x^{(i)}_0, x^{(i)}_1)-y^{(i)})^2$<br>\n",
    "$\\phantom{.....}= \\Sigma_{i=0}^{m}\\frac{\\partial}{\\partial\\theta_0}(h(x^{(i)}_0, x^{(i)}_1)-y^{(i)})^2$<br>\n",
    "$\\phantom{.....}= \\Sigma_{i=0}^{m}\\frac{\\partial}{\\partial\\theta_0}(\\theta_0 x_0 + \\theta_1 x_1 - y^{(i)})^2$<br>\n",
    "$\\phantom{.....}= \\Sigma_{i=0}^{m}2\\cdot (\\theta^{(i)}_0 x^{(i)}_0 + \\theta^{(i)}_1 x^{(i)}_1 - y^{(i)})\\cdot x^{(i)}_0$<br>\n",
    "\n",
    "Similarly\n",
    "\n",
    "$\\frac{\\partial}{\\partial\\theta_1}J = \\Sigma_{i=0}^{m}2\\cdot (\\theta^{(i)}_0 x^{(i)}_0 + \\theta^{(i)}_1 x^{(i)}_1 - y^{(i)})\\cdot x^{(i)}_1$\n",
    "\n",
    "Therefore, $(\\frac{\\partial}{\\partial\\theta_0}J, \\frac{\\partial}{\\partial\\theta_1}J)$ is a vector that is in the direction of steepest ascent for our loss function. Conversely, $-(\\frac{\\partial}{\\partial\\theta_0}J, \\frac{\\partial}{\\partial\\theta_1}J)$ is the direction of steepest descent of our loss function.\n",
    "\n",
    "Following this idea, we can iteratively nudge our parameter vector in the direction of the negative gradient to improve the accuracy of our model over time by using the rule\n",
    "\n",
    "$\\theta_0 := \\theta_0 - \\alpha_0\\Sigma_{i=0}^{m}(\\theta^{(i)}_0 x^{(i)}_0 + \\theta^{(i)}_1 x^{(i)}_1 - y^{(i)})\\cdot x^{(i)}_0$<br>\n",
    "$\\theta_1 := \\theta_1 - \\alpha_1\\Sigma_{i=0}^{m}(\\theta^{(i)}_0 x^{(i)}_0 + \\theta^{(i)}_1 x^{(i)}_1 - y^{(i)})\\cdot x^{(i)}_1$\n",
    "\n",
    "Descend is a function $f: \\mathbb{R}^2 \\to \\mathbb{R}^2$, in our case descend will bring a vector containg our two parameters, and use the data set to compute and return an updated vector of parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 1.3251x + 7.8542 estimates the line of best fit after 20000 iterations\n"
     ]
    }
   ],
   "source": [
    "def run() -> None:\n",
    "    params = [0, 0]\n",
    "    for i in range(ITERATIONS):\n",
    "        params = descend(params)\n",
    "    params = list(map(lambda x: \"%.4f\"%x, params))\n",
    "    print(f'y = {params[0]}x + {params[1]} estimates the line of best fit after {ITERATIONS} iterations')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
